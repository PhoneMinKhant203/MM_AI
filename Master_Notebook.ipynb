{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czLV47clWmvD"
      },
      "outputs": [],
      "source": [
        "# SETUP & INSTALLATION\n",
        "!pip install datasets transformers sentence-transformers faiss-cpu torch\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "from torch.utils.data import DataLoader\n",
        "import faiss\n",
        "import pickle\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL532HSdXNdd"
      },
      "outputs": [],
      "source": [
        "# LOAD & PREPARE DATA\n",
        "print(\"Loading Datasets...\")\n",
        "\n",
        "# Load Medicine Data\n",
        "url = \"https://raw.githubusercontent.com/MinSiThu/Burmese-Microbiology-1K/main/data/Microbiology.csv\"\n",
        "medicine_df = pd.read_csv(url)\n",
        "med_questions = medicine_df['Instruction'].tolist()\n",
        "med_answers = medicine_df['Output'].tolist()\n",
        "\n",
        "# Load Agriculture Data\n",
        "dataset = load_dataset(\"chuuhtetnaing/myanmar-instruction-tuning-dataset\")\n",
        "def is_agriculture(example):\n",
        "    keywords = [\"လယ်သမား\", \"စိုက်ပျိုးရေး\", \"လယ်ယာ\", \"စပါး\", \"ပင်ပေါက်\", \"သစ်တော\", \"ရေမြေ\", \"သီးနှံ\", \"သတ်မှတ်ချက်\", \"သစ်ပင်\"]\n",
        "    return any(keyword in example['inputs'] for keyword in keywords)\n",
        "\n",
        "agriculture_dataset = dataset['train'].filter(is_agriculture)\n",
        "agri_questions = agriculture_dataset['inputs']\n",
        "agri_answers = agriculture_dataset['targets']\n",
        "\n",
        "# Combine for Training\n",
        "# convert Q&A pairs into \"InputExample\" format for the model\n",
        "train_examples = []\n",
        "\n",
        "# Add Medicine pairs\n",
        "for q, a in zip(med_questions, med_answers):\n",
        "    train_examples.append(InputExample(texts=[str(q), str(a)]))\n",
        "\n",
        "# Add Agriculture pairs\n",
        "for q, a in zip(agri_questions, agri_answers):\n",
        "    train_examples.append(InputExample(texts=[str(q), str(a)]))\n",
        "\n",
        "print(f\"Total Training Pairs: {len(train_examples)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP4utPi0XZfz"
      },
      "outputs": [],
      "source": [
        "# FINE-TUNE THE MODEL\n",
        "print(\"Loading Pre-trained Model...\")\n",
        "# start with the base multilingual model\n",
        "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "# Create a DataLoader\n",
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
        "\n",
        "# Define Loss Function\n",
        "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
        "\n",
        "# Train the model\n",
        "print(\"Starting Fine-Tuning (This updates the neural network)...\")\n",
        "model.fit(\n",
        "    train_objectives=[(train_dataloader, train_loss)],\n",
        "    epochs=4,\n",
        "    warmup_steps=100,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "\n",
        "# Save the FINE-TUNED model\n",
        "output_path = \"./fine_tuned_burmese_model\"\n",
        "model.save(output_path)\n",
        "print(f\"Fine-tuned model saved to: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI9D4eIsaWVs"
      },
      "outputs": [],
      "source": [
        "# RE-GENERATE FAISS INDEXES (Using NEW Model)\n",
        "print(\"Regenerating FAISS Indexes with the new brain...\")\n",
        "\n",
        "# Function to save index and answers\n",
        "def create_index(questions, answers, name):\n",
        "    embeddings = model.encode(questions, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings)\n",
        "\n",
        "    # Save Index\n",
        "    faiss.write_index(index, f\"{name}_faiss.index\")\n",
        "\n",
        "    # Save Answers\n",
        "    with open(f\"{name}_answers.pkl\", \"wb\") as f:\n",
        "        pickle.dump(answers, f)\n",
        "    print(f\"Saved {name} index and answers.\")\n",
        "\n",
        "# create Medicine Index\n",
        "create_index(med_questions, med_answers, \"medicine\")\n",
        "\n",
        "# create Agriculture Index\n",
        "create_index(agri_questions, agri_answers, \"agriculture\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gpmVZNcaxuz"
      },
      "outputs": [],
      "source": [
        "# ZIP FILES FOR DOWNLOAD\n",
        "!zip -r my_project_data.zip fine_tuned_burmese_model medicine_faiss.index medicine_answers.pkl agriculture_faiss.index agriculture_answers.pkl\n",
        "print(\"All files zipped! Download 'my_project_data.zip' from the files tab.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbsW16Ldeyxu"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a folder in Drive to store the project\n",
        "import os\n",
        "destination_folder = \"/content/drive/My Drive/Burmese_AI_Model\"\n",
        "\n",
        "if not os.path.exists(destination_folder):\n",
        "    os.makedirs(destination_folder)\n",
        "    print(f\"Created folder: {destination_folder}\")\n",
        "\n",
        "# Copy the zip file to Google Drive\n",
        "import shutil\n",
        "source_file = \"my_project_data.zip\"\n",
        "destination_path = f\"{destination_folder}/my_project_data.zip\"\n",
        "\n",
        "if os.path.exists(source_file):\n",
        "    shutil.copy(source_file, destination_path)\n",
        "    print(f\"Success! File saved to Google Drive at: {destination_path}\")\n",
        "else:\n",
        "    print(\"Error: Could not find 'my_project_data.zip'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mrBTmyProdC"
      },
      "outputs": [],
      "source": [
        "!pip install datasets pandas\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import pickle\n",
        "\n",
        "print(\"Repairing Medicine Data...\")\n",
        "# Repair Medicine\n",
        "url = \"https://raw.githubusercontent.com/MinSiThu/Burmese-Microbiology-1K/main/data/Microbiology.csv\"\n",
        "medicine_df = pd.read_csv(url)\n",
        "# Force conversion to simple string list\n",
        "med_answers = [str(x) for x in medicine_df['Output'].tolist()]\n",
        "\n",
        "with open(\"medicine_answers.pkl\", \"wb\") as f:\n",
        "    pickle.dump(med_answers, f)\n",
        "\n",
        "print(\"Repairing Agriculture Data...\")\n",
        "# Repair Agriculture\n",
        "dataset = load_dataset(\"chuuhtetnaing/myanmar-instruction-tuning-dataset\")\n",
        "\n",
        "def is_agriculture(example):\n",
        "    keywords = [\"လယ်သမား\", \"စိုက်ပျိုးရေး\", \"လယ်ယာ\", \"စပါး\", \"ပင်ပေါက်\", \"သစ်တော\", \"ရေမြေ\", \"သီးနှံ\", \"သတ်မှတ်ချက်\", \"သစ်ပင်\"]\n",
        "    return any(keyword in example['inputs'] for keyword in keywords)\n",
        "\n",
        "# Filter again\n",
        "agriculture_dataset = dataset['train'].filter(is_agriculture)\n",
        "\n",
        "\n",
        "agri_answers = [str(x) for x in agriculture_dataset['targets']]\n",
        "\n",
        "with open(\"agriculture_answers.pkl\", \"wb\") as f:\n",
        "    pickle.dump(agri_answers, f)\n",
        "\n",
        "print(\"SUCCESS! Clean files created.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
